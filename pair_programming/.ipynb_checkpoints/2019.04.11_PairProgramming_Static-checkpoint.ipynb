{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static\n",
    "\n",
    "\n",
    "\n",
    "By now you're familiar with the typical use of linear regression: you're given a dataframe with a bunch of features and a set of observations for each feature. You then take one feature (your y) and try to predict it based on other features (your x's). \n",
    "\n",
    "This generally works to a certain extent. This morning, though, we're going to set up a rather strange problem for linear regression. We will see what happens when y and the x's are totally unrelated.\n",
    "\n",
    "Recall that regression follows the formula \n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\epsilon\n",
    "$$ \n",
    "When we \"fit\" an OLS model we are giving the model all of the x's and the y and asking it to find the best betas.\n",
    "\n",
    "This time, however, we're going to set all the betas to zero \n",
    "$$\n",
    "\\beta_0=\\beta_1=\\dots=0\n",
    "$$\n",
    "and then fit an OLS model.\n",
    "\n",
    "Before we do this, stop and think for a second:\n",
    "\n",
    "- What do you expect the model to do? What will the betas/r-squared/p-values that it finds look like?\n",
    "> R2 would stay zero. Variability in the target, but the model is doing nothing, so it's unable to account for any of that behavior.\n",
    "- What do you think the model *should* do? Is that different from what you think it *will* do?\n",
    "> in practice, get better results than expected due to the nature of randomness (bound to see patterns in data)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/5/5a/No_Signal_23.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "Generate simulation data. We want to have 200 points (observations) for the y feature and for 20 x features. In other words make sure `y.shape == (200,1)` and `x.shape == (200,20)`. The x's should be randomly generated independent of each other. And the y should be randomly generated independent of the x's. \n",
    "\n",
    "Use statsmodels to fit an OLS model to your data. Are the results as you expected? Do you have any betas with a $p<0.05$? If not, re-run the model until you do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import patsy #patsy takes dataframe, turns into matrices, if using sklearn, then it's in a format that\n",
    "#sklearn understands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 200\n",
    "y = np.random.randint(0,200,200)\n",
    "x = np.random.randit(0,200,[200,20])\n",
    "x_name_list = []\n",
    "for item in range(1,21):\n",
    "    x_name_list.append('X' + str(item))\n",
    "x_df = pd.DataFrame(x, columns = x_name_list)\n",
    "x_df.insert(loc=0,column = 'Y', value = y)\n",
    "df = x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_hacking(num_rows):\n",
    "   y=np.random.randint(0,200,200)\n",
    "   x=np.random.randint(0,200,[200,20])\n",
    "   x_name_list=list()\n",
    "   for item in range(1,21):\n",
    "       x_name_list.append(‘X’ + str(item))\n",
    "   x_df=pd.DataFrame(x,columns = x_name_list)\n",
    "\n",
    "   x_df.insert(loc=0, column=‘Y’, value=y)\n",
    "   df=x_df.iloc[:num_rows,:]\n",
    "   df\n",
    "   # Create your feature matrix (X) and target vector (y)\n",
    "   y, x = patsy.dmatrices(‘Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 +X9 +X10+ X11+ X12+ X13+ X14+ X15+ X16+ X17 +X18+ X19+ X20’, data=df, return_type=“dataframe”)\n",
    "\n",
    "   # Create your model\n",
    "   model = sm.OLS(y, x)\n",
    "\n",
    "   # Fit your model to your training set\n",
    "   fit = model.fit()\n",
    "\n",
    "   # # Print summary statistics of the model’s performance\n",
    "   fit.summary()\n",
    "   #np.log(fit.rsquared)\n",
    "   np.log(np.abs(fit.rsquared_adj))\n",
    "   return\n",
    "Message Input\n",
    "\n",
    "\n",
    "Message Jeremy Chow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(1,200):\n",
    "    y = np.random.randn(200,1)\n",
    "    x = np.random.randn(200,i)\n",
    "    model = sm.OLS(y,x)\n",
    "    fit = model.fit()\n",
    "    output.append([fit.rsquared,fit.rsquared_adj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your feature matrix (X) and target vector (y)\n",
    "y, X = patsy.dmatrices('Y ~ X1 + X2 + X3 + X4 + X5 + X6', data=df, return_type=\"dataframe\")\n",
    "\n",
    "# Create your model\n",
    "model = sm.OLS(y, X)\n",
    "\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "Now, automate the process! Run the above analysis but vary the number of x's from 1 to 200. Log the r2 and r2-adj for each case and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
